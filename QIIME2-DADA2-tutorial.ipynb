{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QIIME2 + DADA2  Demo\n",
    "\n",
    "Modified from Amplicons Lesson 3a created by Dr. Liz Suter as part of the BVCN (2020)\n",
    "\n",
    "This is a demo of running QIIME2 in a JupyterLab, utilizing DADA2 to call ASVs.\n",
    "\n",
    "This analysis replicates AstrobioMike's [amplicon analysis tutorial](https://astrobiomike.github.io/amplicon/dada2_workflow_ex#the-data) but by substituting a QIIME2 pipeline.  \n",
    "_____\n",
    "\n",
    "### General workflow\n",
    "\n",
    "1. Initial Steps\n",
    "\t- Organizing your working environment\n",
    "\t- Checking your installations\n",
    "\n",
    "2. Import fastq files into QIIME2\n",
    "3. Remove primers\n",
    "4. Check quality of trimmed reads\n",
    "5. DADA2\n",
    "\t- Denoise\n",
    "\t- Generate the error model\n",
    "\t- Dereplicate\n",
    "\t- Remove chimeras\n",
    "\t- Merge reads\n",
    "\t- Infer ASVs\n",
    "\t- Generate the count table\n",
    "6. Assign Taxonomy\n",
    "7. Create a phylogenetic tree\n",
    "8. Export from QIIME2 and save\n",
    "\n",
    "\n",
    "_____\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "_____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Steps\n",
    "\n",
    "You should be able to see the `qiime2_wd` folder in our current Binder environment, which has all of our fastq files in qiime2 format.\n",
    "\n",
    "\n",
    "Make a 'work' directory where all the generated files for this analysis will go. Move this notebook to that folder as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mkdir work/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform two different types of commands, \"normal\" Python commands (happen inside the Python notebook) and bash commands (using `!`) (which call the Linux command line):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "\n",
    "### Check the QIIME2 installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use a Python tool called qiime2. This is a pre-loaded plugin that let's us view qiime2 graphics in the notebook directly. We need to import this using python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qiime2 as q2\n",
    "# This is now a Python item (instead of bash) and doesn't need to be preceeded by `!`. We will use it a few lines down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import fastq files into qiime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import fastq files into a qiime2 qza file format\n",
    "\n",
    "! qiime tools import \\\n",
    "  --type 'SampleData[PairedEndSequencesWithQuality]' \\\n",
    "  --input-path qiime2_wd/qiime_import \\\n",
    "  --input-format CasavaOneEightSingleLanePerSampleDirFmt \\\n",
    "  --output-path work/demux-paired-end.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove primers \n",
    "We want to call the same program as in Happy Belly, cutadapt, but call it from within qiime2 (documentation [here](https://github.com/qiime2/q2-cutadapt)). The [syntax](https://docs.qiime2.org/2020.2/plugins/available/cutadapt/?highlight=cutadapt) is a little different in qiime2 but we want to do the same thing. Here, we want to use the `trim-paired` method since these sequences are paired-end and already demulitplexed.\n",
    "\n",
    "Check out how to set the parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime cutadapt trim-paired"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How cutadapt functions for us:\n",
    "From forward reads, delete forward primer from 5' end with `--p-front-f` \n",
    "and delete the reverse complement of reverse primer from 3' end with `--p-adapter-f`\n",
    "\n",
    "From reverse reads, delete reverse primer from 5' end with `--p-front-r`\n",
    "and delete the reverse complement of the forward primer from the 3' `--with p-adapter-r`\n",
    "\n",
    "The minimum length (set with --p-minimum-length) should be 215 \n",
    "According to Happy Belly, based roughly on 10% smaller than would be expected after trimming \n",
    "\n",
    "`--p-discard-untrimmed` states to throw away reads that donâ€™t have the primers in them in the expected locations.\n",
    "\n",
    "Run this as `--verbose` so we can see the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime cutadapt trim-paired \\\n",
    "--i-demultiplexed-sequences work/demux-paired-end.qza \\\n",
    "--p-cores 16 \\\n",
    "--p-front-f GTGCCAGCMGCCGCGGTAA \\\n",
    "--p-adapter-f ATTAGAWACCCBDGTAGTCC \\\n",
    "--p-front-r GGACTACHVGGGTWTCTAAT \\\n",
    "--p-adapter-r TTACCGCGGCKGCTGGCAC \\\n",
    "--p-minimum-length 215 \\\n",
    "--p-discard-untrimmed \\\n",
    "--o-trimmed-sequences work/demux-paired-end-trimmed.qza #\\\n",
    "--verbose "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can comment out the `--verbose` option to keep the notebook clean but you can run it to see the results of primer trimming. More than 99% of the sequences get trimmed for all sample files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check quality of trimmed reads\n",
    "Qiime2 works with special 'qzv' files for data visualizations. To read a much better description of these, see this [page](https://docs.qiime2.org/2020.2/concepts/#data-files-visualizations). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the summarize function to summarize the trimmed reads\n",
    "! qiime demux summarize \\\n",
    "--i-data work/demux-paired-end-trimmed.qza \\\n",
    "--o-visualization work/demux-paired-end-trimmed.qzv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize\n",
    "\n",
    "<u>If you are working in your local terminal</u>, you can view the above file using the command `qiime tools view demux-paired-end-trimmed.qzv`. An html will pop up with the interactive plot. You can also drag the file directly into [this website](https://view.qiime2.org/).\n",
    "\n",
    "<u>If you are working in the VICE app</u> in a Jupyter notebook, one of the benefits is that qiime2 visualization tool that we imported above. We can view the interactive plot directly in this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.Visualization.load(\"demux-paired-end-trimmed.qzv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "Click around in the above interactive plot quality scores at different positions, number of sequences in different samples, etc.\n",
    "\n",
    "\n",
    "From the visualization above, we can see the same things that are laid out in the Happy Belly tutorial: that, for the forward reads, the quality really drops off at about 250bp and for the reverse reads, at about 200."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DADA2 \n",
    "Use DADA2 to denoises paired-end sequences, dereplicate them, and filter chimeras, all in one step.\n",
    "\n",
    "In the Happy Belly tutorial, DADA2 is implemented through R. This let's you control many of the parameters and is multiple steps. Within Qiime2, we just have one DADA2 step, which quality trims, generates the error model, dereplicates, removes chimeras, merges reads, infers ASVs, and generates the count table all in one step. The drawback is that here we have less control over the detailed parameters. For this example it should not impact our results, but depending on your goals, you can always go deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the documentation on dada2 in qiime2:\n",
    "!qiime dada2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to use the denoise-paired option. \n",
    "\n",
    "# Next check which input parameters we can modfiy in that option:\n",
    "\n",
    "!qiime dada2 denoise-paired "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose some parameters:\n",
    "\n",
    "\n",
    "Goal: Replicate the parameters used in Happy Belly:\n",
    "\n",
    "- --p-trunc-len-f: truncate the F reads at position 250 \n",
    "- --p-trunc-len-r: truncate the R reads at position 200  \n",
    "    - Reads shorter than these will be thrown out\n",
    "\n",
    "- DADA2 also filters out reads using maxEE, a threshold number of expected errors in each read\n",
    "    - For Happy Belly, they threw out reads if they were likely to have more than 2 erroneous base calls \n",
    "    - Here, the documentation says 2 is the default so I won't even put that parameter in. \n",
    "    - If you wanted to change it, you would use the --p-max-ee-f and --p-max-ee-r arguments\n",
    "\n",
    "- --p-trunc-q can be used to truncate reads when the quality score drops below a certain threshold. \n",
    "    - The default number is 2, which is the value I want so I also won't be assigning that parameter         \n",
    "- --p-chimera-method: I will also leave the default 'consensus' method\n",
    "\n",
    "- --p-n-threads I am going to put 0 here, which means: use all available threads.\n",
    "\n",
    "- --p-n-reads-learn DADA2 tries to estimate how many errors were generated by the sequencer based on an error model. This parameters sets how many sequences go into training the model. Leave the default here as 1,000,000 for now\n",
    "\n",
    "\n",
    "- --verbose will show us what's happening as it's running.\n",
    "\n",
    "\n",
    "**Note**: This is the longest step and may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime dada2 denoise-paired \\\n",
    "--i-demultiplexed-seqs work/demux-paired-end-trimmed.qza \\\n",
    "--p-trunc-len-f 250 \\\n",
    "--p-trunc-len-r 200 \\\n",
    "--p-n-threads 0 \\\n",
    "--output-dir work/DADA2_denoising_output \\\n",
    "--verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the results \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime metadata tabulate \\\n",
    "  --m-input-file work/DADA2_denoising_output/denoising_stats.qza \\\n",
    "  --o-visualization work/DADA2_denoising_output/denoising_stats.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.Visualization.load(\"work/DADA2_denoising_output/denoising_stats.qzv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WE can compare the above table to the `summary_tab` [table from Happy Belly](https://astrobiomike.github.io/amplicon/dada2_workflow_ex#overview-of-counts-throughout).  \n",
    "\n",
    "Our tables look different for a number of reasons: \n",
    "* we had a few more input sequences, which was probably due to slightly different cutadapt parameters\n",
    "* the filtering steps here removed several more due to the chimera removal method we used (eg. 'consensus' vs 'pool') or a parameter that we were unable to set through the qiime2 (eg. setting a min length of 175)\n",
    "\n",
    "This highlights how much small changes can impact the result, but not the interpretation of the data. These methods all \"correct\" -- learning the nuances can be a long endeavor, but do not need to restrict your biological interpretations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a look at a summary of the remaining sequence reads (**Note** - in the outpute of the rep_seq visualization you can click directly on a sequence to send it to Blast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime feature-table tabulate-seqs \\\n",
    "--i-data work/DADA2_denoising_output/representative_sequences.qza \\\n",
    "--o-visualization work/DADA2_denoising_output/rep_seqs.qzv \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.Visualization.load(\"work/DADA2_denoising_output/rep_seqs.qzv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And take a look at the feature table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime feature-table summarize \\\n",
    "--i-table work/DADA2_denoising_output/table.qza \\\n",
    "--o-visualization work/DADA2_denoising_output/table.qzv \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.Visualization.load(\"work/DADA2_denoising_output/table.qzv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign taxonomy \n",
    "\n",
    "We are going to assign taxonomy based on a reference database. These reference databases are called \"classifiers\" and drawn from curated databases, such as the one from [SILVA](https://www.arb-silva.de/).\n",
    "\n",
    "You can dowload the classifier directly or train it yourself. Since the dataset we are working with uses common primers, there are classifiers that already exist.  If you are using other primers, or want to train your own reference database for some other reason, you should follow the instructions on this [page](https://docs.qiime2.org/2020.2/tutorials/feature-classifier/).\n",
    "\n",
    "Here we are going to use  SILVA v132 as our reference database. This is the most recent qiime2-compatible classifier and is the same one used in Happy Belly. I am just going to download the 16S rRNA v4 (515F/806R) v132 classifier from [here](https://docs.qiime2.org/2021.4/data-resources/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, assign taxononomy using the SILVA classifier (this step also takes awhile...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://data.qiime2.org/2019.10/common/silva-132-99-515-806-nb-classifier.qza\n",
    "! mv silva-132-99-515-806-nb-classifier.qza work/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime feature-classifier classify-sklearn \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below takes a long time to run (>1 hr)..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And try to assign taxonomy again\n",
    "\n",
    "# Classify the representative sequences\n",
    "! qiime feature-classifier classify-sklearn \\\n",
    "--i-classifier work/silva-132-99-515-806-nb-classifier.qza \\\n",
    "--i-reads work/DADA2_denoising_output/representative_sequences.qza \\\n",
    "--output-dir work/classified_sequences \\\n",
    "--verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and visualize\n",
    "! qiime metadata tabulate \\\n",
    "  --m-input-file work/classified_sequences/classification.qza \\\n",
    "  --o-visualization work/classified_sequences/taxonomy.qzv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q2.Visualization.load(\"work/classified_sequences/taxonomy.qzv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create phylogenetic tree \n",
    "\n",
    "Next, we are going to make a phylogenetic tree file with our representative sequences. This is useful for some downstream analyses such as UniFrac.\n",
    "\n",
    "In QIIME2, you can make an alignment *de novo* or align to a reference tree. To see further description of each of these, see the QIIME2 tutorial [here](https://docs.qiime2.org/2019.10/tutorials/phylogeny/).  Here, I will use the de novo approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make new directory for results of alignment\n",
    "! mkdir work/phylogeny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next make a multiple sequence alignment with MAFFT ([documentation](https://docs.qiime2.org/2020.2/plugins/available/alignment/mafft/))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime alignment mafft \\\n",
    "  --i-sequences work/DADA2_denoising_output/representative_sequences.qza \\\n",
    "  --o-alignment work/phylogeny/aligned-rep-seqs.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you want to mask the alignment, which reduces noise from ambigously aligned regions (see qiime2 link above for more detail):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime alignment mask \\\n",
    "  --i-alignment work/phylogeny/aligned-rep-seqs.qza \\\n",
    "  --o-masked-alignment work/phylogeny/masked-aligned-rep-seqs.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next is constructing the phylogeny. I will use fasttree here, but there are multiple options, all described in the linked QIIME2 page above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime phylogeny fasttree \\\n",
    "  --i-alignment work/phylogeny/masked-aligned-rep-seqs.qza \\\n",
    "  --o-tree work/phylogeny/fasttree-tree.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, you must root the tree in order to be able to use it in UniFrac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime phylogeny midpoint-root \\\n",
    "  --i-tree work/phylogeny/fasttree-tree.qza \\\n",
    "  --o-rooted-tree work/phylogeny/fasttree-tree-rooted.qza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that all of the steps above (mafft alignment> mask> fasttree> midpoint root) could have been run with one command, `align-to-tree-mafft-fasttree`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export\n",
    "\n",
    "Next, like in Happy Belly, we want to export the major files we generated for downstream analyses: 1) the count table (aka feature table/ ASV table/ OTU table), 2) the fasta file, and 3) the taxonomy file. In addition, I will also export the tree file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime tools export \\\n",
    "  --input-path work/DADA2_denoising_output/table.qza \\\n",
    "  --output-path work/export/table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above file is in [BIOM format](http://biom-format.org/documentation/format_versions/biom-2.1.html). You may want to put in in tsv format is you are going to be using it in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! biom convert \\\n",
    "-i work/export/table/feature-table.biom \\\n",
    "-o work/export/table/table.tsv --to-tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Next export the fasta files with the representative sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime tools export \\\n",
    "  --input-path work/DADA2_denoising_output/representative_sequences.qza \\\n",
    "  --output-path work/export/rep-seqs.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Export the taxonomy file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime tools export \\\n",
    "  --input-path work/classified_sequences/classification.qza \\\n",
    "  --output-path work/export/taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) And lastly the tree file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! qiime tools export \\\n",
    "  --input-path work/phylogeny/fasttree-tree-rooted.qza \\\n",
    "  --output-path work/export/exported-tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save\n",
    "\n",
    "And that's it! Our results files are all in the 'export' folder. You can dowload these directly to your local computer by right-clicking on the folder object on the left."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
